<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Root cause analysis (RCA) of latencies in a microservice architecture &mdash; DoWhy | An end-to-end library for causal inference  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Contributing to DoWhy" href="../contributing/index.html" />
    <link rel="prev" title="Basic Example for GCM-Based Inference" href="gcm_basic_example.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> DoWhy | An end-to-end library for causal inference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/intro.html">Introduction to DoWhy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_simple_example.html">Quick-start notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/comparison.html">Comparison to other packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/cite.html">Citing this package</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/causality_intro.html">Introduction to causality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/four_steps_causality.html">Effect inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="nb_index.html">Example notebooks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials/Case studies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial-causalinference-machinelearning-using-dowhy-econml.html">CATE estimation with DoWhy+EconML</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_example_effect_of_memberrewards_program.html">Effect of membership rewards program</a></li>
<li class="toctree-l1"><a class="reference internal" href="DoWhy-The%20Causal%20Story%20Behind%20Hotel%20Booking%20Cancellations.html">Understanding hotel booking cancellations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GCM-based inference (Experimental)</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../gcm/user_guide/index.html">GCMs User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_basic_example.html">Basic Example for GCM-Based Inference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Root cause analysis (RCA) of latencies in a microservice architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Setting-up-the-causal-graph">Setting up the causal graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Scenario-1:-Observing-a-single-outlier">Scenario 1: Observing a single outlier</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Attributing-an-outlier-latency-at-a-target-service-to-other-services">Attributing an outlier latency at a target service to other services</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Scenario-2:-Observing-permanent-degradation-of-latencies">Scenario 2: Observing permanent degradation of latencies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Attributing-permanent-degradation-of-latencies-at-a-target-service-to-other-services">Attributing permanent degradation of latencies at a target service to other services</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Scenario-3:-Simulating-the-intervention-of-shifting-resources">Scenario 3: Simulating the intervention of shifting resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Appendix:-Data-generation-process">Appendix: Data generation process</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">Contributing to DoWhy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code_repo.html">Code repository &amp; Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dowhy.html">dowhy package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DoWhy | An end-to-end library for causal inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../gcm/index.html">&lt;no title&gt;</a> &raquo;</li>
      <li>Root cause analysis (RCA) of latencies in a microservice architecture</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/example_notebooks/rca_microservice_architecture.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Root-cause-analysis-(RCA)-of-latencies-in-a-microservice-architecture">
<h1>Root cause analysis (RCA) of latencies in a microservice architecture<a class="headerlink" href="#Root-cause-analysis-(RCA)-of-latencies-in-a-microservice-architecture" title="Permalink to this heading"></a></h1>
<p>In this case study, we identify the root causes of “unexpected” observed latencies in cloud services that empower an online shop. We focus on the process of placing an order, which involves different services to make sure that the placed order is valid, the customer is authenticated, the shipping costs are calculated correctly, and the shipping process is initiated accordingly. The dependencies of the services is shown in the graph below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from IPython.display import Image
Image(&#39;microservice-architecture-dependencies.png&#39;, width=500)
</pre></div>
</div>
</div>
<p>This kind of dependency graph could be obtained from services like <a class="reference external" href="https://aws.amazon.com/xray/">Amazon X-Ray</a> or defined manually based on the trace structure of requests.</p>
<p>We assume that the dependency graph above is correct and that we are able to measure the latency (in seconds) of each node for an order request. In case of <code class="docutils literal notranslate"><span class="pre">Website</span></code>, the latency would represent the time until a confirmation of the order is shown. For simplicity, let us assume that the services are synchronized, i.e., a service has to wait for downstream services in order to proceed. Further, we assume that two nodes are not impacted by unobserved factors (hidden confounders) at the same time
(i.e., causal sufficiency). Seeing that, for instance, network traffic affects multiple services, this assumption might be typically violated in a real-world scenario. However, weak confounders can be neglected, while stronger ones (like network traffic) could falsely render multiple nodes as root causes. Generally, we can only identify causes that are part of the data.</p>
<p>Under these assumptions, the observed latency of a node is defined by the latency of the node itself (intrinsic latency), and the sum over all latencies of direct child nodes. This could also include calling a child node multiple times.</p>
<p>Let us load data with observed latencies of each node.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import pandas as pd

normal_data = pd.read_csv(&quot;rca_microservice_architecture_latencies.csv&quot;)
normal_data.head()
</pre></div>
</div>
</div>
<p>Let us also take a look at the pair-wise scatter plots and histograms of the variables.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>axes = pd.plotting.scatter_matrix(normal_data, figsize=(10, 10), c=&#39;#ff0d57&#39;, alpha=0.2, hist_kwds={&#39;color&#39;:[&#39;#1E88E5&#39;]});
for ax in axes.flatten():
    ax.xaxis.label.set_rotation(90)
    ax.yaxis.label.set_rotation(0)
    ax.yaxis.label.set_ha(&#39;right&#39;)
</pre></div>
</div>
</div>
<p>In the matrix above, the plots on the diagonal line are histograms of variables, whereas those outside of the diagonal are scatter plots of pair of variables. The histograms of services without a dependency, namely <code class="docutils literal notranslate"><span class="pre">Customer</span> <span class="pre">DB</span></code>, <code class="docutils literal notranslate"><span class="pre">Product</span> <span class="pre">DB</span></code>, <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">DB</span></code> and <code class="docutils literal notranslate"><span class="pre">Shipping</span> <span class="pre">Cost</span> <span class="pre">Service</span></code>, have shapes similar to one half of a Gaussian distribution. The scatter plots of various pairs of variables (e.g., <code class="docutils literal notranslate"><span class="pre">API</span></code> and <code class="docutils literal notranslate"><span class="pre">www</span></code>, <code class="docutils literal notranslate"><span class="pre">www</span></code> and <code class="docutils literal notranslate"><span class="pre">Website</span></code>, <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">Service</span></code> and <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">DB</span></code>) show linear
relations. We shall use this information shortly to assign generative causal models to nodes in the causal graph.</p>
<section id="Setting-up-the-causal-graph">
<h2>Setting up the causal graph<a class="headerlink" href="#Setting-up-the-causal-graph" title="Permalink to this heading"></a></h2>
<p>If we look at the <code class="docutils literal notranslate"><span class="pre">Website</span></code> node, it becomes apparent that the latency we experience there depends on the latencies of all downstream nodes. In particular, if one of the downstream nodes takes a long time, <code class="docutils literal notranslate"><span class="pre">Website</span></code> will also take a long time to show an update. Seeing this, the causal graph of the latencies can be built by inverting the arrows of the service graph.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import networkx as nx
from dowhy import gcm

causal_graph = nx.DiGraph([(&#39;www&#39;, &#39;Website&#39;),
                           (&#39;Auth Service&#39;, &#39;www&#39;),
                           (&#39;API&#39;, &#39;www&#39;),
                           (&#39;Customer DB&#39;, &#39;Auth Service&#39;),
                           (&#39;Customer DB&#39;, &#39;API&#39;),
                           (&#39;Product Service&#39;, &#39;API&#39;),
                           (&#39;Auth Service&#39;, &#39;API&#39;),
                           (&#39;Order Service&#39;, &#39;API&#39;),
                           (&#39;Shipping Cost Service&#39;, &#39;Product Service&#39;),
                           (&#39;Caching Service&#39;, &#39;Product Service&#39;),
                           (&#39;Product DB&#39;, &#39;Caching Service&#39;),
                           (&#39;Customer DB&#39;, &#39;Product Service&#39;),
                           (&#39;Order DB&#39;, &#39;Order Service&#39;)])
</pre></div>
</div>
</div>
<div class="alert alert-block alert-info"><p>Here, we are interested in the causal relationships between latencies of services rather than the order of calling the services.</p>
</div><p>We will use the information from the pair-wise scatter plots and histograms to manually assign causal models. In particular, we assign half-Normal distributions to the root nodes (i.e., <code class="docutils literal notranslate"><span class="pre">Customer</span> <span class="pre">DB</span></code>, <code class="docutils literal notranslate"><span class="pre">Product</span> <span class="pre">DB</span></code>, <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">DB</span></code> and <code class="docutils literal notranslate"><span class="pre">Shipping</span> <span class="pre">Cost</span> <span class="pre">Service</span></code>). For non-root nodes, we assign linear additive noise models (which scatter plots of many parent-child pairs indicate) with empirical distribution of noise terms.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from scipy.stats import halfnorm

causal_model = gcm.StructuralCausalModel(causal_graph)

for node in causal_graph.nodes:
    if len(list(causal_graph.predecessors(node))) &gt; 0:
        causal_model.set_causal_mechanism(node, gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()))
    else:
        causal_model.set_causal_mechanism(node, gcm.ScipyDistribution(halfnorm))
</pre></div>
</div>
</div>
<div class="alert alert-block alert-info"><p>Alternatively, we can also automate this <strong>if</strong> we don’t have prior knowledge or are not familiar with the statistical implications:</p>
<blockquote>
<div><p>gcm.auto.assign_causal_mechanisms(causal_model, normal_data)</p>
</div></blockquote>
</div></section>
<section id="Scenario-1:-Observing-a-single-outlier">
<h2>Scenario 1: Observing a single outlier<a class="headerlink" href="#Scenario-1:-Observing-a-single-outlier" title="Permalink to this heading"></a></h2>
<p>Suppose we get an alert from our system where a customer experienced an unusually high latency when an order is placed. Our task is now to investigate this issue and to find the root cause of this behaviour.</p>
<p>We first load the latency to the corresponding alert.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>outlier_data = pd.read_csv(&quot;rca_microservice_architecture_anomaly.csv&quot;)
outlier_data
</pre></div>
</div>
</div>
<p>We are interested in the increased latency of <code class="docutils literal notranslate"><span class="pre">Website</span></code> which the customer directly experienced.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>outlier_data.iloc[0][&#39;Website&#39;]-normal_data[&#39;Website&#39;].mean()
</pre></div>
</div>
</div>
<p>For this customer, <code class="docutils literal notranslate"><span class="pre">Website</span></code> was roughly 2 seconds slower than for other customers on average. Why?</p>
<section id="Attributing-an-outlier-latency-at-a-target-service-to-other-services">
<h3>Attributing an outlier latency at a target service to other services<a class="headerlink" href="#Attributing-an-outlier-latency-at-a-target-service-to-other-services" title="Permalink to this heading"></a></h3>
<p>To answer why <code class="docutils literal notranslate"><span class="pre">Website</span></code> was slower for this customer, we attribute the outlier latency at <code class="docutils literal notranslate"><span class="pre">Website</span></code> to upstream services in the causal graph. We refer the reader to <a class="reference external" href="https://arxiv.org/abs/1912.02724">Janzing et al., 2019</a> for scientific details behind this API. We will calculate a 95% bootstrapped confidence interval of our attributions. In particular, we learn the causal models from a random subset of normal data and attribute the target outlier score using those models, repeating the
process 10 times. This way, the confidence intervals we report account for (a) the uncertainty of our causal models as well as (b) the uncertainty in the attributions due to the variance in the samples drawn from those causal models.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>gcm.config.disable_progress_bars() # to disable print statements when computing Shapley values

median_attribs, uncertainty_attribs = gcm.confidence_intervals(
    gcm.bootstrap_training_and_sampling(gcm.attribute_anomalies,
                                        causal_model,
                                        normal_data,
                                        target_node=&#39;Website&#39;,
                                        anomaly_samples=outlier_data),
    num_bootstrap_resamples=10)
</pre></div>
</div>
</div>
<div class="alert alert-block alert-info"><p>By default, a quantile-based anomaly score is used that estimates the negative log-probability of a sample being normal. This is, the higher the probabilty of an outlier, the larger the score. The library offers different kinds of outlier scoring functions, such as the z-score, where the mean is the expected value based on the causal model.</p>
</div><p>Let us visualize the attributions along with their uncertainty in a bar plot.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
import numpy as np

def bar_plot_with_uncertainty(median_attribs, uncertainty_attribs, ylabel=&#39;Attribution Score&#39;, figsize=(8, 3), bwidth=0.8, xticks=None, xticks_rotation=90):
    fig, ax = plt.subplots(figsize=figsize)
    yerr_plus = [uncertainty_attribs[node][1] - median_attribs[node] for node in median_attribs.keys()]
    yerr_minus = [median_attribs[node] - uncertainty_attribs[node][0] for node in median_attribs.keys()]
    plt.bar(median_attribs.keys(), median_attribs.values(), yerr=np.array([yerr_minus, yerr_plus]), ecolor=&#39;#1E88E5&#39;, color=&#39;#ff0d57&#39;, width=bwidth)
    plt.xticks(rotation=xticks_rotation)
    plt.ylabel(ylabel)
    ax.spines[&#39;right&#39;].set_visible(False)
    ax.spines[&#39;top&#39;].set_visible(False)
    if xticks:
        plt.xticks(list(median_attribs.keys()), xticks)
    plt.show()

bar_plot_with_uncertainty(median_attribs, uncertainty_attribs)
</pre></div>
</div>
</div>
<p>The attributions indicate that <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> is the main driver of high latency in <code class="docutils literal notranslate"><span class="pre">Website</span></code> which is expected as we perturb the causal mechanism of <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> to generate an outlier latency in <code class="docutils literal notranslate"><span class="pre">Website</span></code> (see Appendix below). Attributions to <code class="docutils literal notranslate"><span class="pre">Customer</span> <span class="pre">DB</span></code> and <code class="docutils literal notranslate"><span class="pre">Product</span> <span class="pre">Service</span></code> can be explained by misspecification of causal models. First, some of the parent-child relationships in the causal graph are non-linear (by looking at the scatter matrix). Second, the parent
child-relationship between <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> and <code class="docutils literal notranslate"><span class="pre">Product</span> <span class="pre">DB</span></code> seems to indicate two mechanisms. This could be due to an unobserved binary variable (e.g., Cache hit/miss) that has a multiplicative effect on <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code>. An additive noise cannot capture the multiplicative effect of this unobserved variable.</p>
</section>
</section>
<section id="Scenario-2:-Observing-permanent-degradation-of-latencies">
<h2>Scenario 2: Observing permanent degradation of latencies<a class="headerlink" href="#Scenario-2:-Observing-permanent-degradation-of-latencies" title="Permalink to this heading"></a></h2>
<p>In the previous scenario, we attributed a <em>single</em> outlier latency in <code class="docutils literal notranslate"><span class="pre">Website</span></code> to services that are nodes in the causal graph, which is useful for anecdotal deep dives. Next, we consider a scenario where we observe a permanent degradation of latencies and we want to understand its drivers. In particular, we attribute the change in the average latency of <code class="docutils literal notranslate"><span class="pre">Website</span></code> to upstream nodes.</p>
<p>Suppose we get additional 1000 requests with higher latencies as follows.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>outlier_data = pd.read_csv(&quot;rca_microservice_architecture_anomaly_1000.csv&quot;)
outlier_data.head()
</pre></div>
</div>
</div>
<p>We are interested in the increased latency of <code class="docutils literal notranslate"><span class="pre">Website</span></code> on average for 1000 requests which the customers directly experienced.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>outlier_data[&#39;Website&#39;].mean() - normal_data[&#39;Website&#39;].mean()
</pre></div>
</div>
</div>
<p>The <em>Website</em> is slower on average (by almost 2 seconds) than usual. Why?</p>
<section id="Attributing-permanent-degradation-of-latencies-at-a-target-service-to-other-services">
<h3>Attributing permanent degradation of latencies at a target service to other services<a class="headerlink" href="#Attributing-permanent-degradation-of-latencies-at-a-target-service-to-other-services" title="Permalink to this heading"></a></h3>
<p>To answer why <code class="docutils literal notranslate"><span class="pre">Website</span></code> is slower for those 1000 requests compared to before, we attribute the change in the average latency of <code class="docutils literal notranslate"><span class="pre">Website</span></code> to services upstream in the causal graph. We refer the reader to <a class="reference external" href="https://assets.amazon.science/b6/c0/604565d24d049a1b83355921cc6c/why-did-the-distribution-change.pdf">Budhathoki et al., 2021</a> for scientific details behind this API. As in the previous scenario, we will calculate a 95% bootstrapped confidence interval of our attributions and visualize
them in a bar plot.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>median_attribs, uncertainty_attribs = gcm.confidence_intervals(
    lambda : gcm.distribution_change(causal_model,
                                     normal_data.sample(frac=0.6),
                                     outlier_data.sample(frac=0.6),
                                     &#39;Website&#39;,
                                     difference_estimation_func=lambda x, y: np.mean(y) - np.mean(x)),
    num_bootstrap_resamples = 10)

bar_plot_with_uncertainty(median_attribs, uncertainty_attribs)
</pre></div>
</div>
</div>
<p>We observe that <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> is the root cause that slowed down <code class="docutils literal notranslate"><span class="pre">Website</span></code>. In particular, the method we used tells us that the change in the causal mechanism (i.e., the input-output behaviour) of <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> (e.g., Caching algorithm) slowed down <code class="docutils literal notranslate"><span class="pre">Website</span></code>. This is also expected as the outlier latencies were generated by changing the causal mechanism of <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> (see Appendix below).</p>
</section>
</section>
<section id="Scenario-3:-Simulating-the-intervention-of-shifting-resources">
<h2>Scenario 3: Simulating the intervention of shifting resources<a class="headerlink" href="#Scenario-3:-Simulating-the-intervention-of-shifting-resources" title="Permalink to this heading"></a></h2>
<p>Next, let us imagine a scenario where permanent degradation has happened as in scenario 2 and we’ve successfully identified <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> as the root cause. Furthermore, we figured out that a recent deployment of the <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> contained a bug that is causing the overloaded hosts. A proper fix must be deployed, or the previous deployment must be rolled back. But, in the meantime, could we mitigate the situation by shifting over some resources from <code class="docutils literal notranslate"><span class="pre">Shipping</span> <span class="pre">Service</span></code> to
<code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code>? And would that help? Before doing it in reality, let us simulate it first and see whether it improves the situation.</p>
<p><img alt="d4d89a9c256e4f559bb6052c3056a861" class="no-scaled-link" src="../_images/shifting-resources.png" style="width: 600px;" /></p>
<p>Let’s perform an intervention where we say we can reduce the average time of <code class="docutils literal notranslate"><span class="pre">Caching</span> <span class="pre">Service</span></code> by 1s. But at the same time we buy this speed-up by an average slow-down of 2s in <code class="docutils literal notranslate"><span class="pre">Shipping</span> <span class="pre">Cost</span> <span class="pre">Service</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>median_mean_latencies, uncertainty_mean_latencies = gcm.confidence_intervals(
    lambda : gcm.bootstrap_training_and_sampling(gcm.interventional_samples,
                                                 causal_model,
                                                 outlier_data,
                                                 interventions = {
                                                    &quot;Caching Service&quot;: lambda x: x-1,
                                                    &quot;Shipping Cost Service&quot;: lambda x: x+2
                                                 },
                                                 observed_data=outlier_data)().mean().to_dict(),
    num_bootstrap_resamples=10)
</pre></div>
</div>
</div>
<p>Has the situation improved? Let’s visualize the results.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>avg_website_latency_before = outlier_data.mean().to_dict()[&#39;Website&#39;]
bar_plot_with_uncertainty(dict(before=avg_website_latency_before, after=median_mean_latencies[&#39;Website&#39;]),
                          dict(before=np.array([avg_website_latency_before, avg_website_latency_before]), after=uncertainty_mean_latencies[&#39;Website&#39;]),
                          ylabel=&#39;Avg. Website Latency&#39;,
                          figsize=(3, 2),
                          bwidth=0.4,
                          xticks=[&#39;Before&#39;, &#39;After&#39;],
                          xticks_rotation=45)
</pre></div>
</div>
</div>
<p>Indeed, we do get an improvement by about 1s. We’re not back at normal operation, but we’ve mitigated part of the problem. From here, maybe we can wait until a proper fix is deployed.</p>
</section>
<section id="Appendix:-Data-generation-process">
<h2>Appendix: Data generation process<a class="headerlink" href="#Appendix:-Data-generation-process" title="Permalink to this heading"></a></h2>
<p>The scenarios above work on synthetic data. The normal data was generated using the following functions:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from scipy.stats import truncexpon, halfnorm


def create_observed_latency_data(unobserved_intrinsic_latencies):
    observed_latencies = {}
    observed_latencies[&#39;Product DB&#39;] = unobserved_intrinsic_latencies[&#39;Product DB&#39;]
    observed_latencies[&#39;Customer DB&#39;] = unobserved_intrinsic_latencies[&#39;Customer DB&#39;]
    observed_latencies[&#39;Order DB&#39;] = unobserved_intrinsic_latencies[&#39;Order DB&#39;]
    observed_latencies[&#39;Shipping Cost Service&#39;] = unobserved_intrinsic_latencies[&#39;Shipping Cost Service&#39;]
    observed_latencies[&#39;Caching Service&#39;] = np.random.choice([0, 1], size=(len(observed_latencies[&#39;Product DB&#39;]),),
                                                             p=[.5, .5]) * \
                                            observed_latencies[&#39;Product DB&#39;] \
                                            + unobserved_intrinsic_latencies[&#39;Caching Service&#39;]
    observed_latencies[&#39;Product Service&#39;] = np.maximum(np.maximum(observed_latencies[&#39;Shipping Cost Service&#39;],
                                                                  observed_latencies[&#39;Caching Service&#39;]),
                                                       observed_latencies[&#39;Customer DB&#39;]) \
                                            + unobserved_intrinsic_latencies[&#39;Product Service&#39;]
    observed_latencies[&#39;Auth Service&#39;] = observed_latencies[&#39;Customer DB&#39;] \
                                         + unobserved_intrinsic_latencies[&#39;Auth Service&#39;]
    observed_latencies[&#39;Order Service&#39;] = observed_latencies[&#39;Order DB&#39;] \
                                          + unobserved_intrinsic_latencies[&#39;Order Service&#39;]
    observed_latencies[&#39;API&#39;] = observed_latencies[&#39;Product Service&#39;] \
                                + observed_latencies[&#39;Customer DB&#39;] \
                                + observed_latencies[&#39;Auth Service&#39;] \
                                + observed_latencies[&#39;Order Service&#39;] \
                                + unobserved_intrinsic_latencies[&#39;API&#39;]
    observed_latencies[&#39;www&#39;] = observed_latencies[&#39;API&#39;] \
                                + observed_latencies[&#39;Auth Service&#39;] \
                                + unobserved_intrinsic_latencies[&#39;www&#39;]
    observed_latencies[&#39;Website&#39;] = observed_latencies[&#39;www&#39;] \
                                    + unobserved_intrinsic_latencies[&#39;Website&#39;]

    return pd.DataFrame(observed_latencies)


def unobserved_intrinsic_latencies_normal(num_samples):
    return {
        &#39;Website&#39;: truncexpon.rvs(size=num_samples, b=3, scale=0.2),
        &#39;www&#39;: truncexpon.rvs(size=num_samples, b=2, scale=0.2),
        &#39;API&#39;: halfnorm.rvs(size=num_samples, loc=0.5, scale=0.2),
        &#39;Auth Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.2),
        &#39;Product Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.2),
        &#39;Order Service&#39;: halfnorm.rvs(size=num_samples, loc=0.5, scale=0.2),
        &#39;Shipping Cost Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.2),
        &#39;Caching Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.1),
        &#39;Order DB&#39;: truncexpon.rvs(size=num_samples, b=5, scale=0.2),
        &#39;Customer DB&#39;: truncexpon.rvs(size=num_samples, b=6, scale=0.2),
        &#39;Product DB&#39;: truncexpon.rvs(size=num_samples, b=10, scale=0.2)
    }


normal_data = create_observed_latency_data(unobserved_intrinsic_latencies_normal(10000))
</pre></div>
</div>
</div>
<p>This simulates the latency relationships under the assumption of having synchronized services and that there are no hidden aspects that impact two nodes at the same time. Furthermore, we assume that the Caching Service has to call through to the Product DB only in 50% of the cases (i.e., we have a 50% cache miss rate). Also, we assume that the Product Service can make calls in parallel to its downstream services Shipping Cost Service, Caching Service, and Customer DB and join the threads when
all three service have returned.</p>
<div class="alert alert-block alert-info"><p>We use truncated exponential and half-normal distributions, since their shapes are similar to distributions observed in real services.</p>
</div><p>The anomalous data is generated in the following way:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def unobserved_intrinsic_latencies_anomalous(num_samples):
    return {
        &#39;Website&#39;: truncexpon.rvs(size=num_samples, b=3, scale=0.2),
        &#39;www&#39;: truncexpon.rvs(size=num_samples, b=2, scale=0.2),
        &#39;API&#39;: halfnorm.rvs(size=num_samples, loc=0.5, scale=0.2),
        &#39;Auth Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.2),
        &#39;Product Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.2),
        &#39;Order Service&#39;: halfnorm.rvs(size=num_samples, loc=0.5, scale=0.2),
        &#39;Shipping Cost Service&#39;: halfnorm.rvs(size=num_samples, loc=0.1, scale=0.2),
        &#39;Caching Service&#39;: 2 + halfnorm.rvs(size=num_samples, loc=0.1, scale=0.1),
        &#39;Order DB&#39;: truncexpon.rvs(size=num_samples, b=5, scale=0.2),
        &#39;Customer DB&#39;: truncexpon.rvs(size=num_samples, b=6, scale=0.2),
        &#39;Product DB&#39;: truncexpon.rvs(size=num_samples, b=10, scale=0.2)
    }

outlier_data = create_observed_latency_data(unobserved_intrinsic_latencies_anomalous(1000))
</pre></div>
</div>
</div>
<p>Here, we significantly increased the average time of the <em>Caching Service</em> by two seconds, which coincides with our results from the RCA. Note that a high latency in <em>Caching Service</em> would lead to a constantly higher latency in upstream services. In particular, customers experience a higher latency than usual.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="gcm_basic_example.html" class="btn btn-neutral float-left" title="Basic Example for GCM-Based Inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../contributing/index.html" class="btn btn-neutral float-right" title="Contributing to DoWhy" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, PyWhy contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>